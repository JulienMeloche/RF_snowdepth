{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snow depth prediction with topographic parameters\n",
    "From the article:\n",
    "High-resolution snow depth prediction using Random Forest algorithm with topographic parameters: A case study in the Greiner watershed, Nunavut\n",
    "\n",
    "Meloche et al 2022 \n",
    "https://doi.org/10.1002/hyp.14546\n",
    "\n",
    "The first section trains the RF algorithm with topographic parameter. (see csv file)\n",
    "\n",
    "I suggest you create an env with those library\n",
    "\n",
    "### Python Library:\n",
    "- Numpy\n",
    "- pandas\n",
    "- seaborn and pyplot (for graph)\n",
    "- scikit learn for Random forest\n",
    "\n",
    "for prediction and creating snow depth map in .tiff\n",
    "- xarray\n",
    "- rasterio\n",
    "- rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "import rioxarray\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the function that will run scikit Random forest\n",
    "def randomForest(X, y, training_size=0.5):\n",
    "    \"\"\"\n",
    "    X: array of input variable (predictor)\n",
    "    y: snow depth for training\n",
    "    \n",
    "    return:\n",
    "    regressor : (obj type) to get feature importance\n",
    "    y_test, x_test : numpy array, x and y for testing accuracy\n",
    "    y_pred :  numpy array, y for prediction\n",
    "    \"\"\"\n",
    "    #test size is set to 50% by default, modify to your liking when calling function\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= training_size, random_state = 0)\n",
    "    print(f'train : {len(y_train)}, test : {len(y_test)}')\n",
    "    # no difference with standard\n",
    "    #sc = StandardScaler()\n",
    "    #X_train = sc.fit_transform(X_train)\n",
    "    #X_test = sc.transform(X_test)\n",
    "\n",
    "    regressor = RandomForestRegressor(n_estimators=400, n_jobs = -1, random_state=0)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print(f'Explained Variance : {metrics.explained_variance_score(y_test, y_pred)} ')\n",
    "    print(f'RÂ² : {metrics.r2_score(y_test, y_pred)} ')\n",
    "    \n",
    "    return regressor, y_test, y_pred, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get (X, y) data for training\n",
    "#X topo parameter \n",
    "#y snow depth from magnaprobe\n",
    "df_corr = pd.read_csv('magnaprobe_clean_Greiner.csv')\n",
    "df_corr.columns\n",
    "\n",
    "# the parameters chosen are the most optimal, user can use more if wanted or play with parameters\n",
    "X = pd.DataFrame({'Sx' : df_corr.Sx_mean, 'TPI_150m' : df_corr.TPI_mean, 'Slope' : df_corr.slope_mean, \n",
    "                  #'Aspect' : df_corr.aspect_mea,\n",
    "                  #'Elevation' : df_corr.elev_mean, \n",
    "                  'Ecotype' : df_corr.Eco_majori, \n",
    "                  #'Veg Height' : df_corr.Veg_height,\n",
    "                  #'NDVI' : df.ndvi_mean,\n",
    "                  'Year mean' : df_corr.u_sd_temp,\n",
    "                  #'TPI_500' : df_corr.TPI_500_me,\n",
    "                  #'TPI_1km' : df_corr.TPI_1000_m,\n",
    "                  'TPI_5km' : df_corr.TPI_5km_me,\n",
    "                  #'TPI_10km' : df_corr.TPI_10km_m,\n",
    "                 })\n",
    "\n",
    "# get dpeth fro training\n",
    "y = df_corr.loc[:,\"depth\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the training algorithm\n",
    "#get accuracy\n",
    "regressor, y_test, y_pred, X_test = randomForest(X,y)\n",
    "hist_y_corr = regressor.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "label = ['Sx', 'TPI', 'slope', 'Ecotype', 'Year mean', 'TPI_5km']\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(label, hist_y_corr)\n",
    "plt.ylabel('Feature importance', size = 15)\n",
    "plt.title('Random Forest variable', size = 15)\n",
    "plt.yticks(size = 12)\n",
    "plt.xticks(size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph validation from RF prediction\n",
    "\n",
    "#sns.set('paper')\n",
    "plt.figure(figsize = (12,4))\n",
    "plt.subplot(121)\n",
    "plt.title('a)', size = 20)\n",
    "x = np.linspace(0,1.5,100)\n",
    "plt.plot(x,x, color = 'black')\n",
    "plt.xlim(0,1.5)\n",
    "plt.ylim(0,1.5)\n",
    "plt.yticks(size = 12)\n",
    "plt.xticks(size = 12)\n",
    "plt.ylabel('Snow depth modeled (m)', size = 15)\n",
    "plt.xlabel('Snow depth measured (m)', size = 15)\n",
    "plt.scatter(y_test, y_pred, color = 'red', alpha = 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('b)', size = 20)\n",
    "sns.residplot(x = y_test, y = y_pred)\n",
    "plt.ylabel('Residuals (m)', size = 15)\n",
    "plt.xlabel('Snow depth (m)', size =15)\n",
    "plt.yticks(size = 12)\n",
    "plt.xticks(size = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input for entire watershed\n",
    "This section is to run the random forest across the full watershed.\n",
    "\n",
    "The output is in raster format (.tiff), EPSG = 26913 (NAD83 / UTM zone 13N)\n",
    "\n",
    "X or topographic parameters comes in netcdf format (RF_variable_GreinerWatershed.nc)\n",
    "\n",
    "for prediction of new snowmap, the mean depth is define by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average depth per year is use for training\n",
    "#average depth needs to be provided for prediction\n",
    "snowdepth_mean = 0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open dataset of topographic parameter for prediction\n",
    "#data cube\n",
    "data = xr.open_dataset('RF_variable_GreinerWatershed.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data (X variable) (flatten array for prediction)\n",
    "tmp_tpi = data.TPI_150m.values.flatten()\n",
    "tmp_sx = data.Sx_R100_W315.values.flatten()\n",
    "tmp_slope = data.slope.values.flatten()\n",
    "tmp_elev = data.elev.values.flatten()\n",
    "tmp_eco = data.eco.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get shape of raster\n",
    "shape = data.TPI_150m.values.shape\n",
    "#get index of pixel for correspondace of value predicted by RF\n",
    "XX,YY = np.meshgrid(np.arange(shape[1]),np.arange(shape[0]))\n",
    "\n",
    "#remove water value from prediction in RF with ecotype 1,2 and 3\n",
    "eco = data.eco.values\n",
    "indexx, indexy = np.where(eco == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set array for year mean, same len of other parameter\n",
    "y_mean = np.ones(len(tmp_sx)) * snowdepth_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building X and Y variable for prediction\n",
    "#order of Variable needs to match regressor from training data\n",
    "X_data = pd.DataFrame({'Sx' : tmp_sx, 'TPI' : tmp_tpi, 'Slope' : tmp_slope,\n",
    "                       #'Aspect' : tmp_aspect, \n",
    "                       'Elevation' : tmp_elev,\n",
    "                       'Ecotype' : tmp_eco,\n",
    "                       'Year mean' : y_mean,\n",
    "                       'XX' : XX.flatten(), 'YY' : YY.flatten()}).dropna()\n",
    "\n",
    "# get index inforamtion\n",
    "XX_clean = np.array(X_data.XX)\n",
    "YY_clean = np.array(X_data.YY)\n",
    "X_data = X_data.drop(labels = ['XX', 'YY'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict snow depth \n",
    "Y_pred = regressor.predict(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array with original shape \n",
    "arr = np.zeros(shape)\n",
    "arr.fill(np.nan)\n",
    "# fill with prediction from Y_pred and corresponding index\n",
    "for i in np.arange(len(XX_clean)):\n",
    "    arr[YY_clean[i], XX_clean[i]] = Y_pred[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set ecotype of water to nan for transprancy in QGIS\n",
    "indexx, indexy = np.where(eco == 1)\n",
    "arr[(indexx, indexy)]=np.nan\n",
    "indexx, indexy = np.where(eco == 2)\n",
    "arr[(indexx, indexy)]=np.nan\n",
    "indexx, indexy = np.where(eco == 3)\n",
    "arr[(indexx, indexy)]=np.nan\n",
    "\n",
    "#create xarray dataset to write tiff file\n",
    "snow = xr.DataArray(arr, coords = [data.eco.y.values, data.eco.x.values], dims = [ 'y', 'x'])\n",
    "#write tiff file\n",
    "snow.rio.write_crs(\"epsg:26913\", inplace=True)\n",
    "snow.rio.to_raster(\"Ecotype_Greiner_snowRF.tif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
